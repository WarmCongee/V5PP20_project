# V5PP 20级ROS仿真入门项目说明文档
如果您也是刚开始学习ROS，可以尝试根据该README运行修改一个集导航，视觉，策略控制在内的完整的仿真工程。了解一个完整的入门工程，相信会对你的ROS学习有很大的帮助。当然该工程还有很多方面尚待优化完善，如果你有任何问题，可以在Issues中说明，或者通过邮件联系。可以是提出任何建议或任何问题，我们会很乐意一起交流学习。

如果需要直接运行该工程，下载仓库中的功能包到catkin工作空间后看3.0和4.5中的信息即可。

## 1. Introduction - 介绍

### 1.0 项目起源

本工程是NPU足球机器人基地V5++组，自20级开始的新队员入队ROS仿真入门实践项目，该项目限定时间为一个月。

旨在通过ROS仿真实践，学习ROS基础，视觉处理，导航避障，Gazebo机器人与场地仿真等方向的基础知识，以及实践通过**Git仓库**进行团队的项目管理，由新队员**自主分工**选择负责内容和学习方向，通过**团队协作**完成项目。

### 1.1 项目要求

安装Ubuntu18.04和ROS\melodic，基于ROS与Gazebo仿真平台实现仿真功能，其他所需功能包及平台可以自由选择。

根据需求在gazebo中搭建场地和小车。利用ROS的相关功能使小车能够识别不同颜色的小球并控制其行驶碰撞小球，然后利用雷达等传感器使小车能够规避障碍区到达地图上的指定坐标

### 1.2 更新记录

2021.6.5   1.0版上传

### 1.3 视频样例

<video id="video" controls=""src="工程样例.mp4" preload="none">


<video id="video" controls=""src="gazebo仿真.mp4" preload="none">


## 2. Summary-摘要

### 2.0 功能应用的主体、功能包以及算法

项目的工程代码由python编写。

仿真机器人模型由xacro特殊xml文件描述，主体应用了修改后的mbot机器人，装配了仿真深度相机以及仿真雷达。

视觉处理：相机获取RGB的图像通过形状以及颜色检测来获得小球的中心的像素坐标。

导航避障：基于movebase功能包进行避障，先后使用了Gmapping和Hector功能包进行建图。

策略逻辑：根据视觉传来的话题消息，得到小球的中心像素坐标，通过PID差速控制进行追球。并在视觉判定成功撞到球后，发布goal消息给导航，机器人自主导航避障到达目标点。

## 3.Requirements - 必要条件

### 3.0 元功能包下载

本工程基于ROS\melodic版本完成，如果你想尝试运行该工程时，请执行以下操作。

```bash
sudo apt-gat upgrate

sudo apt-get update

sudo apt-get install ros-melodic-navigation     #下载navigation导航元功能包（内部包括move_base，gmapping，AMCL功能包）

sudo apt-get install ros-melodic-cv-bridge       #下载用于视觉处理的cv-bridge功能包

 cd ~/.gazebo/                                                        #访问gazebo隐藏文件夹

mkdir -p models                                                    #新建models文件夹用于存储模型

cd ~/.gazebo/models/                                         

wget http://file.ncnynl.com/ros/gazebo_models.txt           #下载gazebo官方模型库（本仿真项目应用了官方的部分模型）

wget -i gazebo_models.txt

ls model.tar.g* | xargs -n1 tar xzvf                                         #解压安装包
```

### 3.1所用的元功能包：

gmapping：基于激光雷达，Rao-Blackwellzed粒子滤波算法，需要里程计信息，即时定位与地图建模。

cartographer：google开源，主要基于激光雷达，二维或三维条件下定位与建图。

ros_melodic_navigation:基于move_base的导航框架，包括全局局部规划，本地实时规划。

amcl：蒙特卡罗定位，针对已有地图跟踪一个机器人的姿态。

cv_bridge：视觉处理功能包

### 3.2功能包：

 mbot_description:包含机器人的描述文件，相关传感器的描述文件，附带相应的launch文件（在gazebo中展示）。

mbot_gazebo:包含了仿真环境的描述文件，以及用于启动总项目，经整合后的launch文件。

mbot_navigation：实现机器人导航运动的关键，movebase节点的参数设置，gmapping，amcl，hector的参数设置，以及对应的launch文件，同时导航部分的工程代码也位于此处。

robot_vision：实现视觉的功能包，识别目标，控制机器人撞球的工程代码，参数文件位于此处。

## 4. Configuration - 配置运行（怎么跑起来）

### 4.0 机器人的配置

主要应用了mbot机器人，同时装配了相机和摄像头，并进行了机器人参数的调整修改。

### 4.1 仿真环境的搭建

根据需求，在gazebo中搭建建筑场地和模型，并根据需要应用了gazebo官方模型库中的模型文件，模型的很多更改在

### 4.2 导航的参数设置

主要运用了gmapping建图，amcl定位和move_base导航避障控制。

调整movebase的yaml配置文件，调整move_base的效果

配置建图：调节建图时地图更新速度（不能过大过小），调整建图的障碍判定范围（防止卡墙角），使机器人的运动流畅。

配置tf转换：实现顺利导航的关键，采用静态坐标转换，避免机器人的定位不准的问题，保证机器人平滑运动。

配置运动控制：调节机器人前进速度，转弯速度，全局规划和局部规划的控制比例，让机器人快速运动而不失误。

### 4.3 视觉的配置

订阅kinect相机的ros话题：/kinect/rgb/image_raw来得到相机传回来的RGB图像

运动：通过发布小球像素点的坐标话题给策略，由策略给小车赋予转向和前行的速度来操控小车运动

### 4.4 策略

根据项目需求，策略基本逻辑为，在终端输入想要追的球颜色，小车寻找球，找到球之后通过PID差速控制其追球。当视觉判定其撞到球之后，策略代码发布目标位置坐标话题给movebase，小车自主导航避障到达目标点。

### 4.5 运行

按如下操作运行该程序

在你的catkin工作空间打开两个终端，以下简称终端一，终端二。

在终端一中执行以下指令：

```bash
catkin_make

source devel/setup.bash

roslaunch mbot_gazebo withmap.launch

#至此会出现gazebo仿真界面，摄像头图像画面，Rviz雷达探测画面
```

在终端二中执行以下指令：

```bash
catkin_make

source devel/setup.bash

rosrun robot_vision move_mrobot.py
```

你将在终端看到如下内容：

```bash
请选择你需要追什么颜色的球
如果你选择红色 请输入：red
如果你选择绿色 请输入：green
如果你选择蓝色 请输入：blue
如果你选择金色 请输入：gold
如果你选择黑色 请输入：black
>_
```

在终端中输入相应颜色就会让小车自动追相应的球啦，撞到球完后小车会自动开始导航避障到达目标点。

## 5.Contribution-贡献

翁宇哲：控制追球运动和发布导航目标位置的代码，搭建地图场地，完善导航功能。

于元宏：实现导航与定位功能，控制机器人到达指定位置。

吕振峰：实现导航与定位功能，修改构建机器人模型。

丁榕：实现视觉功能，识别对应目标，传输信息。

## 6.Problems-实现过程中遇到的问题及解决的方法

### 6.0该工程中还有很多问题需要解决优化，目前为我们实现功能的第一版，以后有空可能会更新优化一下

### 6.1搭建场地：

1.在场地的搭建过程中需要涉及，sdf和world等文件格式的修改，需要简单学习mxl的语法规则

2.要注意对模型物理参数的配置如质量重力等等，保证满足工程需求。

### 6.2搭建小车模型： ##################

 使用已存在的的二轮机器人为基础完成任务，机器人的结构不符合需求：学习机器人描述文件的格式，对机器人进行适当修改。

### 6.3视觉：

1.python语法不规范不熟悉：通过参考CSDN上的python代码以及编译器上的报错来改正自己的错误；

2.对于相应函数的使用不熟悉：通过查阅CSDN上的帖子以及查阅毛星云的opencv3编程入门来甲申对于函数使用的熟悉程度以及i甲申对于函数原理的了解；

3.调节相应颜色上下阙值的问题：通过参考CSDN上的相应颜色上下阙值的经验值再加上自己的分析调节，对于受到环境颜色干扰较大的物体，通过鼠标点击确定图像上相应点的hsv值的问题来确定上下阙值的大小。

4.对于圆形检测不准确的问题：开始的时候用了霍夫圆检测的方法，对于某些角度的圆的形状检测不出来，通过学长学姐教授的面积比算法来检测圆更加快速也更加容易实现（代码少了很多），检测圆更加的准确；

5.订阅和发布消息的实现不熟悉：通过多问队友（队友超级强！！！！）来解决问题；

### 6.4导航：

1.机器人运动不平稳顺滑：查阅资料了解movebase参数意义，反复修改参数。

2.机器人tf变换不准确：更换获得tf变换的方法。

3.建图不准确，有多余或漂移：修改参数，缩小地图更新间隔，纠正偏差。

4.急转弯贴墙行驶导致卡墙角：适当调整全局规划和本地规划的控制比例，增强避障能力。

## 7.Feelings-感想

丁榕：做完这次任务感觉整个人都升华了，学到了很多东西，ros从0到现在比较了解，视觉调参的有了新的心得体会。真的丰富了知识，增加了经验，也明白了自己还有很多不会的东西，开始思考如何在传统的算法上有新的创新，使得机器人以更好的性能达到更好的效果。

吕振峰，于元宏：学习到了Linux系统的操作，ros的使用，对机器人slam的整体框架形成了认知，了解和尝试使用建图和定位的几个功能包，感觉收获蛮多。

## 8.Acknowledgments-致谢

做为刚接触ROS一个月的Rookie，我们在ROS的学习和实践中遇到了很多问题。感谢基地各方向学长学长学姐推荐和提供的资料，并对我们遇到的问题给予的解答与帮助。古月的教程真的非常友好，对我们有很大的帮助。
